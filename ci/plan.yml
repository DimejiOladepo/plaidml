---
CONST:
  efficiency_baseline: tf-cuda-gp100gl

  gpu_flops:
    # nvidia
    gt650m: 605.77
    gtx780: 3819.42
    gtx1050: 1733.15
    gtx1070: 7282.69
    gtx1080: 9380.39
    gtx1080ti: 12571.25
    gp100gl: 10736.02
    gv100gl: 14757.70
    # amd
    r560: 1815.01
    rx480: 5950.39
    r9nano: 8077.04
    vega: 12697.10
    gfx900: 11300.84
    gfx803: 3573.79
    gfx906: 13379.70
    vega56: 4342.63
    # mali
    t628: 34.05
    # intel
    hd4000: 247.14
    hd505: 213.80
    hd630: 417.22
    uhd630: 454.72
    iris655: 757.84
    neo: 1084.50

PLATFORMS:
  tf-cuda-gtx780:
    variant: linux_x86_64
  tf-cuda-gtx1070:
    variant: linux_x86_64
  tf-dnnl-cpu:
    variant: linux_x86_64
  pml-mtl-uhd630:
    variant: macos_x86_64
  pml-llvm-cpu:
    variant: linux_x86_64
  tf-cuda-gp100gl:
    variant: linux_x86_64
  pml-ocl-gfx900:
    variant: linux_x86_64
  pml-ocl-gp100gl:
    variant: linux_x86_64
  pml-ocl-gv100gl:
    variant: linux_x86_64
  pml-ocl-gen:
    variant: linux_x86_64
  pml-vk-gen:
    variant: linux_x86_64
  pml-ocl-gfx804:
    variant: windows_x86_64

VARIANTS:
  linux_x86_64_t:
    arch: manylinux1_x86_64
    system: Linux
    env:
      PLAIDML_DEVICE: llvm_cpu.0
      PLAIDML_TARGET: llvm_cpu
  linux_x86_64_dbg_t:
    bazel_config: dbg
    arch: manylinux1_x86_64
    system: Linux
    env:
      PLAIDML_DEVICE: llvm_cpu.0
      PLAIDML_TARGET: llvm_cpu
  macos_x86_64:
    arch: macosx_10_10_x86_64
    system: Darwin
    env:
      PLAIDML_DEVICE: llvm_cpu.0
      PLAIDML_TARGET: llvm_cpu
  macos_x86_64_dbg:
    bazel_config: dbg
    arch: macosx_10_10_x86_64
    system: Darwin
    env:
      PLAIDML_DEVICE: llvm_cpu.0
      PLAIDML_TARGET: llvm_cpu
  # Temporarily remove until build agents are online again
  # windows_x86_64:
  #   arch: win_amd64
  #   system: Windows
  #   env:
  #     PLAIDML_DEVICE: llvm_cpu.0
  #     PLAIDML_TARGET: llvm_cpu

SUITES:
  smoke:
    platforms:
      pml-llvm-cpu:
        pipelines: [nightly, plaidml]
      pml-ocl-gen:
        pipelines: [nightly, plaidml]
    params:
      plaidml:
        batch_sizes: [1]
      ci:
        batch_sizes: [1]
      nightly:
        batch_sizes: [1]
    wheels:
      # NOTE: this list must be in least to most dependent order.
      - plaidml-{version}-py2.py3-none-{arch}.whl
      - plaidml_keras-{version}-py2.py3-none-any.whl
      - plaidbench-{version}-py2.py3-none-any.whl
    timeout: 5
    conda_env: ci/conda/tensorflow.yml
    compare: no
    eventlog: yes
    runner: plaidbench
    args:
      - --results={results}
      - --no-kernel-timing
      - --print-stacktraces
      - --no-warmup
      - --examples=1
      - keras
      - "{workload}"
    workloads:
      resnet50:
        precision: untested

      trivial_model:
        args: [trivial_model_test.py]
        cwd: plaidml/bridge/keras
        precision: untested
        skip_platforms:
          - pml-ocl-gen

  infer:
    platforms:
      pml-llvm-cpu:
        pipelines: [nightly, plaidml, ci]
      pml-ocl-gen:
        pipelines: [nightly, plaidml, ci]
    params:
      ci:
        batch_sizes: [1]
      plaidml:
        batch_sizes: [1]
      nightly:
        batch_sizes: [1]
    wheels:
      # NOTE: this list must be in least to most dependent order.
      - plaidml-{version}-py2.py3-none-{arch}.whl
      - plaidml_keras-{version}-py2.py3-none-any.whl
      - plaidbench-{version}-py2.py3-none-any.whl
    timeout: 10
    conda_env: ci/conda/tensorflow.yml
    runner: plaidbench
    args:
      - --results={results}
      - --batch-size={batch_size}
      - --no-kernel-timing
      - --print-stacktraces
      - keras
      - "{workload}"
    workloads:
      resnet50:
        precision: high
        platform_overrides:
          pml-vk-gen:
            prepend_args: [--examples=128]
            perf_threshold: 0.33
          pml-ocl-gen:
            prepend_args: [--examples=4]
            perf_threshold: 0.33
          pml-llvm-cpu:
            prepend_args: [--examples=128]
          pml-ocl-gfx804:
            prepend_args: [--examples=128]
          pml-mtl-uhd630:
            prepend_args: [--examples=256]
          tf-dnnl-cpu:
            conda_env: ci/conda/tensorflow-dnnl.yml

  train:
    platforms: {}
    params:
      ci:
        batch_sizes: [1, 32]
      nightly:
        batch_sizes: [1, 32]
      train:
        batch_sizes: [16, 32]
    wheels:
      # NOTE: this list must be in least to most dependent order.
      - plaidml-{version}-py2.py3-none-{arch}.whl
      - plaidml_keras-{version}-py2.py3-none-any.whl
      - plaidbench-{version}-py2.py3-none-any.whl
    timeout: 5
    conda_env: ci/conda/ml_gpu.yml
    cwd: plaidbench
    runner: python
    examples: 256
    workloads:
          - resnet50
          - --train
          - --print-stacktraces
          - --batch-size={batch_size}
